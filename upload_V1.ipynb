{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Tutorial with Groclake\n",
        "Description:\n",
        "This complete, end-to-end tutorial demonstrates how to create an Agentic Retrieval-Augmented Generation (RAG) system using Groclake. The process involves managing documents in DataLake, generating vectors for documents, performing vector searches, enriching search results, and utilizing ModelLake to provide contextual, AI-assisted responses. Each step is designed to showcase the capabilities of Groclake in creating a fully functional Agentic RAG system.\n",
        "\n",
        "Groclake Documentation: https://plotch-ai.gitbook.io/groclake-by-plotch.ai\n",
        "\n",
        "Vectorcake is a vector centric infrastructure allowing developers to create embedding vectors quickly, store vectors and build useful RAG applications.\n",
        "\n",
        "Datalake is a data warehouse for storing various types structured and unstructured documents and records. Using Datalake, developers can store pdfs, word documents, excel sheets, google sheets, texts etc for RAG based applications.\n",
        "\n",
        "Modelake is an infrastructure pipe for LLM based operations like chat completions, language translations, automatic speech recognition, text to speech, speech to text and speech to speech operations"
      ],
      "metadata": {
        "id": "3i3YyNwXTKvn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Install the Required Library\n",
        "First, install the groclake library, which will be used for managing data, vectors, and models"
      ],
      "metadata": {
        "id": "t5QydZxVSEp1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uhIfcr6k-vnS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c23da482-0e20-46a4-e68e-54cb6fb5c5ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groclake\n",
            "  Downloading groclake-0.1.14-py3-none-any.whl.metadata (83 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from groclake) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->groclake) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->groclake) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->groclake) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->groclake) (2024.12.14)\n",
            "Downloading groclake-0.1.14-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: groclake\n",
            "Successfully installed groclake-0.1.14\n"
          ]
        }
      ],
      "source": [
        "!pip install groclake"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_J8LJgfsqQ0",
        "outputId": "9c89a89a-a974-42fd-b508-c09a8ba0e58a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/232.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 2: Set Environment Variables\n",
        "Set up the API key and account ID for authenticating with the Groclake service. These are stored as environment variables to simplify access throughout the script."
      ],
      "metadata": {
        "id": "BJeU1xg4SOPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set API key and account ID\n",
        "GROCLAKE_API_KEY = 'fe9fc289c3ff0af142b6d3bead98a923'\n",
        "GROCLAKE_ACCOUNT_ID = '31df8ac36812112e6bc5ff0ad0daf847'\n",
        "\n",
        "# Set them as environment variables\n",
        "os.environ['GROCLAKE_API_KEY'] = GROCLAKE_API_KEY\n",
        "os.environ['GROCLAKE_ACCOUNT_ID'] = GROCLAKE_ACCOUNT_ID\n",
        "\n",
        "print(\"Environment variables set successfully.\")\n"
      ],
      "metadata": {
        "id": "YBQDSTld-xeY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c07c2617-9873-458b-c32f-198882aed909"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment variables set successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2B4pGBVtc65",
        "outputId": "d718e3f0-4e96-4ca0-f84c-4fde0a34c3ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from groclake.vectorlake import VectorLake\n",
        "from groclake.datalake import DataLake\n",
        "from groclake.modellake import ModelLake\n",
        "import random\n",
        "import PyPDF2\n",
        "import docx\n",
        "import textwrap\n",
        "\n",
        "class SarcasticQuizBot:\n",
        "    def __init__(self):\n",
        "        # Initialize API credentials\n",
        "        self.GROCLAKE_API_KEY = '93db85ed909c13838ff95ccfa94cebd9'\n",
        "        self.GROCLAKE_ACCOUNT_ID = '89ff7fa5adc705887aa8186792153342'\n",
        "        self.setup_environment()\n",
        "        self.initialize_lakes()\n",
        "\n",
        "        # Adjusted token limits to leave room for completion\n",
        "        self.MAX_INPUT_TOKENS = 4000  # Reduced from 6000 to safely handle larger documents\n",
        "        self.COMPLETION_TOKENS = 2000\n",
        "        self.CHARS_PER_TOKEN = 4\n",
        "\n",
        "        # Previous roasts, summary_intros, and score_comments remain the same\n",
        "        self.roasts = [\n",
        "            \"Wow, that's impressively wrong! Did you even read the document?\",\n",
        "            \"Oh honey... The answer was right there in the text. Like, literally right there.\",\n",
        "            \"That's about as correct as saying the Earth is flat.\",\n",
        "            \"Amazing! You managed to ignore everything in the document!\",\n",
        "            \"Did you actually read the text, or just use it as a pillow?\",\n",
        "            \"I'm not saying you're wrong, but... actually, yes, I am saying that.\",\n",
        "            \"Congratulations! You've mastered the art of not absorbing information!\",\n",
        "            \"Even a goldfish would remember more from the text!\"\n",
        "        ]\n",
        "\n",
        "        self.summary_intros = [\n",
        "            \"Alright, buckle up buttercup! Here's what this masterpiece is about:\",\n",
        "            \"Oh boy, let me break down this literary gem for you:\",\n",
        "            \"Prepare yourself for this absolutely riveting summary:\",\n",
        "            \"Here's what you apparently couldn't figure out yourself:\",\n",
        "            \"Let me dumb this down to its essence:\",\n",
        "            \"Warning: The following summary contains actual information:\",\n",
        "            \"Behold, the contents of your document, simplified for your convenience:\"\n",
        "        ]\n",
        "\n",
        "        self.score_comments = {\n",
        "            0: \"Wow, a perfect zero! You've truly mastered the art of not learning!\",\n",
        "            1: \"One right answer... Did you actually read the document or just guess?\",\n",
        "            2: \"Two correct! Your reading comprehension is as deep as a parking lot puddle.\",\n",
        "            3: \"Three right! Moving up from 'totally clueless' to just 'mostly clueless'.\",\n",
        "            4: \"Four correct. Are you even trying to understand the material?\",\n",
        "            5: \"Half right! Perfectly balanced between knowledge and ignorance.\",\n",
        "            6: \"Six correct! Starting to show signs of actually reading the document.\",\n",
        "            7: \"Seven! Not bad... for someone who probably skimmed the text.\",\n",
        "            8: \"Eight right! Almost impressive, if I had lower standards.\",\n",
        "            9: \"Nine correct! Who knew you could actually read?\",\n",
        "            10: \"Perfect score! What, did you write this document yourself or something?\"\n",
        "        }\n",
        "\n",
        "    # Setup and initialization methods remain the same\n",
        "    def setup_environment(self):\n",
        "        os.environ['GROCLAKE_API_KEY'] = self.GROCLAKE_API_KEY\n",
        "        os.environ['GROCLAKE_ACCOUNT_ID'] = self.GROCLAKE_ACCOUNT_ID\n",
        "\n",
        "    def initialize_lakes(self):\n",
        "        try:\n",
        "            self.vectorlake = VectorLake()\n",
        "            vector_create = self.vectorlake.create()\n",
        "            self.vectorlake_id = vector_create[\"vectorlake_id\"]\n",
        "\n",
        "            self.datalake = DataLake()\n",
        "            datalake_create = self.datalake.create()\n",
        "            self.datalake_id = datalake_create[\"datalake_id\"]\n",
        "\n",
        "            print(\"Lakes initialized successfully!\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to initialize lakes: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def read_file(self, file_path):\n",
        "        \"\"\"Read different file types and return their content.\"\"\"\n",
        "        try:\n",
        "            file_extension = os.path.splitext(file_path)[1].lower()\n",
        "\n",
        "            if file_extension == '.txt':\n",
        "                with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                    return file.read()\n",
        "\n",
        "            elif file_extension == '.pdf':\n",
        "                text = \"\"\n",
        "                with open(file_path, 'rb') as file:\n",
        "                    pdf_reader = PyPDF2.PdfReader(file)\n",
        "                    for page in pdf_reader.pages:\n",
        "                        text += page.extract_text() + \"\\n\\n\"\n",
        "                return text\n",
        "\n",
        "            elif file_extension in ['.doc', '.docx']:\n",
        "                doc = docx.Document(file_path)\n",
        "                return '\\n\\n'.join([paragraph.text for paragraph in doc.paragraphs])\n",
        "\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported file type: {file_extension}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def chunk_text(self, text):\n",
        "        \"\"\"Improved text chunking that ensures chunks don't exceed token limit.\"\"\"\n",
        "        max_chars = self.MAX_INPUT_TOKENS * self.CHARS_PER_TOKEN\n",
        "        chunks = []\n",
        "\n",
        "        # Split into sentences first (rough approximation)\n",
        "        sentences = [s.strip() for s in text.replace('\\n', ' ').split('.') if s.strip()]\n",
        "\n",
        "        current_chunk = []\n",
        "        current_length = 0\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence_length = len(sentence) + 2  # Add space for period and space\n",
        "\n",
        "            if current_length + sentence_length > max_chars and current_chunk:\n",
        "                # Join current chunk and add to chunks\n",
        "                chunks.append('. '.join(current_chunk) + '.')\n",
        "                current_chunk = [sentence]\n",
        "                current_length = sentence_length\n",
        "            else:\n",
        "                current_chunk.append(sentence)\n",
        "                current_length += sentence_length\n",
        "\n",
        "        # Add the last chunk\n",
        "        if current_chunk:\n",
        "            chunks.append('. '.join(current_chunk) + '.')\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def generate_sassy_summary(self, text):\n",
        "        \"\"\"Generate a summary handling large texts with improved chunking.\"\"\"\n",
        "        try:\n",
        "            chunks = self.chunk_text(text)\n",
        "            summaries = []\n",
        "\n",
        "            # Generate individual summaries for each chunk\n",
        "            for i, chunk in enumerate(chunks):\n",
        "                prompt = (\n",
        "                    f\"Summarize part {i+1} of {len(chunks)} of the text in a sassy, \"\n",
        "                    \"slightly sarcastic, but informative way. Focus on key points:\\n\\n\" + chunk\n",
        "                )\n",
        "\n",
        "                payload = {\n",
        "                    \"messages\": [\n",
        "                        {\n",
        "                            \"role\": \"system\",\n",
        "                            \"content\": \"You are a sassy but knowledgeable assistant who summarizes documents with a mix of snark and actual insight.\"\n",
        "                        },\n",
        "                        {\"role\": \"user\", \"content\": prompt}\n",
        "                    ],\n",
        "                    \"token_size\": self.COMPLETION_TOKENS\n",
        "                }\n",
        "\n",
        "                response = ModelLake().chat_complete(payload)\n",
        "                summaries.append(response[\"answer\"])\n",
        "\n",
        "            # If we have multiple summaries, combine them\n",
        "            if len(summaries) > 1:\n",
        "                # Create a shorter version of each summary for combining\n",
        "                short_summaries = [f\"Part {i+1}: {summary[:1000]}\" for i, summary in enumerate(summaries)]\n",
        "                combine_prompt = (\n",
        "                    \"Combine these partial summaries into one cohesive, sassy summary \"\n",
        "                    \"maintaining the key points and sarcastic tone:\\n\\n\" +\n",
        "                    \"\\n\\n\".join(short_summaries)\n",
        "                )\n",
        "\n",
        "                payload = {\n",
        "                    \"messages\": [\n",
        "                        {\n",
        "                            \"role\": \"system\",\n",
        "                            \"content\": \"You are a sassy but knowledgeable assistant who combines summaries while maintaining style and key points.\"\n",
        "                        },\n",
        "                        {\"role\": \"user\", \"content\": combine_prompt}\n",
        "                    ],\n",
        "                    \"token_size\": self.COMPLETION_TOKENS\n",
        "                }\n",
        "\n",
        "                response = ModelLake().chat_complete(payload)\n",
        "                return response[\"answer\"]\n",
        "\n",
        "            return summaries[0]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating summary: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def generate_question(self, text, question_number):\n",
        "        \"\"\"Generate questions with improved chunk selection.\"\"\"\n",
        "        try:\n",
        "            chunks = self.chunk_text(text)\n",
        "\n",
        "            # Select chunk based on question number to ensure coverage\n",
        "            chunk_index = question_number % len(chunks)\n",
        "            chunk = chunks[chunk_index]\n",
        "\n",
        "            # Ensure the chunk isn't too long for question generation\n",
        "            if len(chunk) > (self.MAX_INPUT_TOKENS * self.CHARS_PER_TOKEN) // 2:\n",
        "                chunk = chunk[:(self.MAX_INPUT_TOKENS * self.CHARS_PER_TOKEN) // 2]\n",
        "\n",
        "            prompt = (\n",
        "                f\"Generate a challenging multiple choice question #{question_number} about this text excerpt. \"\n",
        "                \"The question MUST have EXACTLY 4 options labeled A, B, C, and D. \"\n",
        "                \"Make it specific to the content provided.\\n\\n\"\n",
        "                f\"Text: {chunk}\\n\\n\"\n",
        "                \"Format:\\n\"\n",
        "                \"Question: [Your question here]\\n\"\n",
        "                \"A) [First option]\\n\"\n",
        "                \"B) [Second option]\\n\"\n",
        "                \"C) [Third option]\\n\"\n",
        "                \"D) [Fourth option]\\n\"\n",
        "                \"Correct: [A, B, C, or D]\"\n",
        "            )\n",
        "\n",
        "            payload = {\n",
        "                \"messages\": [\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a quiz bot that generates specific multiple-choice questions about provided text.\"\n",
        "                    },\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                \"token_size\": self.COMPLETION_TOKENS\n",
        "            }\n",
        "\n",
        "            response = ModelLake().chat_complete(payload)\n",
        "            return self._parse_question(response[\"answer\"])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating question: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    # The _parse_question and run_quiz methods remain the same as they don't need modification\n",
        "    def _parse_question(self, response):\n",
        "        \"\"\"Parse the generated question response.\"\"\"\n",
        "        lines = [line.strip() for line in response.split(\"\\n\") if line.strip()]\n",
        "\n",
        "        question = lines[0]\n",
        "        if question.startswith(\"Question:\"):\n",
        "            question = question[9:].strip()\n",
        "\n",
        "        options = []\n",
        "        for line in lines[1:5]:\n",
        "            if line.startswith((\"A)\", \"B)\", \"C)\", \"D)\")):\n",
        "                options.append(line)\n",
        "\n",
        "        correct_answer = None\n",
        "        for line in lines:\n",
        "            if line.startswith(\"Correct:\"):\n",
        "                correct_answer = line.split(\":\")[1].strip()\n",
        "                break\n",
        "\n",
        "        if correct_answer not in [\"A\", \"B\", \"C\", \"D\"]:\n",
        "            correct_answer = \"A\"\n",
        "\n",
        "        return {\n",
        "            \"question\": question,\n",
        "            \"options\": options,\n",
        "            \"correct_answer\": correct_answer\n",
        "        }\n",
        "\n",
        "    def run_quiz(self, text, num_questions=10):\n",
        "        \"\"\"Run the quiz with the provided text.\"\"\"\n",
        "        print(\"\\n\" + random.choice(self.summary_intros))\n",
        "        summary = self.generate_sassy_summary(text)\n",
        "        print(\"\\n\" + textwrap.fill(summary, width=80))\n",
        "\n",
        "        input(\"\\nPress Enter when you're ready to prove how little you retained from that...\")\n",
        "\n",
        "        print(\"\\nAlright, prepare to be humiliated!\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        correct_answers = 0\n",
        "\n",
        "        for i in range(num_questions):\n",
        "            print(f\"\\nQuestion {i+1} of {num_questions}\")\n",
        "            print(\"-\" * 30)\n",
        "\n",
        "            question_data = self.generate_question(text, i+1)\n",
        "            print(question_data[\"question\"])\n",
        "            for option in question_data[\"options\"]:\n",
        "                print(option)\n",
        "\n",
        "            while True:\n",
        "                answer = input(\"\\nYour answer (A/B/C/D): \").upper()\n",
        "                if answer in ['A', 'B', 'C', 'D']:\n",
        "                    break\n",
        "                print(\"Really? It's not that complicated. Just pick A, B, C, or D!\")\n",
        "\n",
        "            if answer == question_data[\"correct_answer\"]:\n",
        "                print(\"\\nCorrect! Who would've thought you actually paid attention!\")\n",
        "                correct_answers += 1\n",
        "            else:\n",
        "                roast = random.choice(self.roasts)\n",
        "                print(f\"\\n{roast}\")\n",
        "                print(f\"The correct answer was {question_data['correct_answer']}.\")\n",
        "\n",
        "            print(f\"\\nCurrent score: {correct_answers}/{i+1}\")\n",
        "\n",
        "        final_score = correct_answers\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(f\"\\nFinal Score: {final_score}/{num_questions}\")\n",
        "        print(self.score_comments[final_score])\n",
        "\n",
        "        if final_score < 5:\n",
        "            print(\"Maybe try actually reading the document next time?\")\n",
        "        elif final_score < 8:\n",
        "            print(\"Not terrible, but not good either. Story of your life?\")\n",
        "        else:\n",
        "            print(\"I hate to admit it, but you might actually have understood the document.\")\n",
        "\n",
        "def main():\n",
        "    quiz_bot = SarcasticQuizBot()\n",
        "\n",
        "    print(\"Welcome to the Sarcastic Document Quiz Bot!\")\n",
        "    print(\"I'll read your document, summarize it with attitude, then test how well you actually read it.\")\n",
        "\n",
        "    while True:\n",
        "        file_path = input(\"\\nEnter the path to your document (or 'quit' to exit): \")\n",
        "        if file_path.lower() == 'quit':\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            document_text = quiz_bot.read_file(file_path)\n",
        "            quiz_bot.run_quiz(document_text)\n",
        "\n",
        "            play_again = input(\"\\nWant to test your reading comprehension on another document? (yes/no): \").lower()\n",
        "            if play_again != 'yes':\n",
        "                print(\"\\nProbably for the best. Your ego couldn't take much more anyway.\")\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nOops! Something went wrong: {str(e)}\")\n",
        "            print(\"Maybe try a file that actually exists next time?\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K3Emmy7TQenQ",
        "outputId": "91712c20-f8cb-4c63-d15a-8977cf9042fe"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lakes initialized successfully!\n",
            "Welcome to the Sarcastic Document Quiz Bot!\n",
            "I'll read your document, summarize it with attitude, then test how well you actually read it.\n",
            "\n",
            "Enter the path to your document (or 'quit' to exit): linea.pdf\n",
            "\n",
            "Let me dumb this down to its essence:\n",
            "\n",
            "Alright, buckle up buttercup, we're diving into the world of matrices, vectors,\n",
            "and all things machine learning. This NITK Surathkal quiz is a whirlwind tour of\n",
            "machine learning foundations, so hold onto your hats.  First off, we're getting\n",
            "quizzed on matrix properties. Apparently, the determinant value isn't a basic\n",
            "property of a matrix, who knew? And all elements are non-negative in a non-\n",
            "negative matrix - shocker, right? A square matrix is the cool kid with equal\n",
            "number of rows and columns.  Then we're thrown into the deep end with linear\n",
            "independence in vector spaces. Turns out, linearly independent vectors are the\n",
            "drama queens of the vector space, spanning the entire thing and refusing to be\n",
            "expressed uniquely as a linear combo of other vectors.  We get a brief interlude\n",
            "with some matrix multiplication and inversion. A and B are multiplied to give us\n",
            "[[19, 22], [43, 50]], and C's inverse is [[0.5, 0], [0, 0.5]].  Then we're onto\n",
            "Singular Value Decomposition (SVD) - it's all about decomposing a matrix into\n",
            "two orthogonal matrices and one diagonal matrix, with the diagonal elements\n",
            "representing the singular values of the matrix. Apparently, machine learning and\n",
            "data science geeks love this stuff.  Next, we delve into the inner product of\n",
            "vectors and their properties. It's a full house with commutative, distributive,\n",
            "associative, and scalar multiplication properties all present.  PCA, or\n",
            "Principal Component Analysis, is all about reducing data dimensionality. The\n",
            "first principal component is the gossip of the data, representing the direction\n",
            "of maximum variance. And before performing PCA, you gotta standardize that data\n",
            "to ensure variance affects the result equally.  Singular matrices are the\n",
            "enigmas of the matrix world, with a determinant equal to zero and no existing\n",
            "inverse. Low-rank matrices are defined by linear dependence among rows or\n",
            "columns, and are important for enhancing computational efficiency.  Orthogonal\n",
            "vectors are the independent thinkers - they must be linearly independent and\n",
            "have a dot product of zero. A subset is considered a subspace in a vector space\n",
            "if it contains the zero vector and is closed under scalar multiplication and\n",
            "vector addition.  Basis vectors are the smallest set of linearly independent\n",
            "vectors that span the entire vector space. And a matrix with all diagonal\n",
            "elements as zero and non-diagonal elements as nonzero is a symmetric matrix.\n",
            "Finally, we're given a matrix D and asked about its singular values, left and\n",
            "right singular vectors, and the shape of the matrix containing left singular\n",
            "vectors. The answers are 40, 1025, 2*2, and [[-0.7071, 0.7071], [0.7071,\n",
            "0.7071]] respectively.  Phew! That was one heck of a ride. But hey, you made it\n",
            "to the end. Give yourself a pat on the back, you've earned it.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-fa521e972350>\u001b[0m in \u001b[0;36m<cell line: 341>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-fa521e972350>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mdocument_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquiz_bot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mquiz_bot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_quiz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mplay_again\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nWant to test your reading comprehension on another document? (yes/no): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-fa521e972350>\u001b[0m in \u001b[0;36mrun_quiz\u001b[0;34m(self, text, num_questions)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtextwrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nPress Enter when you're ready to prove how little you retained from that...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nAlright, prepare to be humiliated!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "actual code\n"
      ],
      "metadata": {
        "id": "Q9vKjWqzRDgU"
      }
    }
  ]
}